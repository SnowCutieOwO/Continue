import{_ as a,c as r,o,b0 as t}from"./chunks/framework.w6NQj85O.js";const k=JSON.parse('{"title":"命令用法","description":"","frontmatter":{},"headers":[],"relativePath":"spark/spark.command-usage.md","filePath":"spark/spark.command-usage.md"}'),i={name:"spark/spark.command-usage.md"};function l(c,e,p,s,d,n){return o(),r("div",null,e[0]||(e[0]=[t('<h1 id="命令用法" tabindex="-1">命令用法 <a class="header-anchor" href="#命令用法" aria-label="Permalink to &quot;命令用法&quot;">​</a></h1><div class="info custom-block"><p class="custom-block-title">注意</p><p><code>/sparkb</code>、<code>/sparkv</code> 和 <code>/sparkc</code> 是 BungeeCord、Velocity 以及 Forge/Fabric 专用的命令，在使用对应服务端时应该将 <code>/spark</code> 替换成上述的命令。</p></div><h2 id="分析器" tabindex="-1">分析器 <a class="header-anchor" href="#分析器" aria-label="Permalink to &quot;分析器&quot;">​</a></h2><h3 id="spark-profiler" tabindex="-1"><code>/spark profiler</code> <a class="header-anchor" href="#spark-profiler" aria-label="Permalink to &quot;`/spark profiler`&quot;">​</a></h3><p>子命令 <code>profiler</code> 可以控制 spark 的分析器。</p><p>执行命令所需权限为 <code>spark 或 </code>spark.profiler`。</p><p>如果分析器已经启动，你可以输入下面这些命令：</p><ul><li><code>/spark profiler open</code> <strong>打开</strong>分析报告页而无需停止；</li><li><code>/spark profiler stop</code> <strong>停止</strong>分析并浏览分析结果；</li><li><code>/spark profiler cancel</code> <strong>取消</strong>分析操作，并取消上传报告。</li></ul><p>在其他情况下，你可以使用这些基本的操作命令：</p><ul><li><code>/spark profiler start</code> 在默认操作模式下<strong>开始</strong>分析；</li><li><code>/spark profiler stop</code> <strong>停止</strong>分析并浏览结果；</li><li><code>/spark profiler info</code> 检查当前分析的<strong>状态</strong>。</li></ul><p>这里还有一些额外的标志参数，可以用于控制分析器。如：</p><ul><li><code>/spark profiler start --timeout &lt;秒&gt;</code> 开始分析，并在给定的时间之后<strong>自动停止</strong>；</li><li><code>/spark profiler start --thread *</code> 开始分析，并记录<strong>所有线程</strong>；</li><li><code>/spark profiler start --alloc</code> 开始分析，并分析内存分配（内存使用情况）而非 CPU 的使用情况。</li></ul><details class="details custom-block"><summary>高级用户参数</summary><p>你可以使用以下命令：</p><ul><li><code>/spark profiler start --interval &lt;毫秒&gt;</code> 开始分析，并按参数中的间隔时间采样（默认值为 4，表示采样间隔为 4 毫秒）；</li><li><code>/spark profiler start --thread *</code> 开始分析，并记录所有线程；</li><li><code>/spark profiler start --thread &lt;线程名称&gt;</code> 开始分析，并记录参数所给定的线程；</li><li><code>/spark profiler start --only-ticks-over &lt;毫秒&gt;</code> 开始分析，但只对时间长度超过给定值的滴答进行采样；</li><li><code>/spark profiler start --regex --thread &lt;正则表达式&gt;</code> 开始分析，且只分析名称符合给定正则表达式的线程；</li><li><code>/spark profiler start --combine-all</code> 开始分析，但将所有线程都组合在一个根节点下；</li><li><code>/spark profiler start --not-combined</code> 开始分析，但禁用来自同一线程池的线程组；</li><li><code>/spark profiler start --force-java-sampler</code> 开始分析，并强制使用 Java 采样而非异步采样；</li><li><code>/spark profiler start --alloc --alloc-live-only</code> 开始分析内存分配，且只保留在结束时仍未被内存回收清理的对象数据；</li><li><code>/spark profiler start --interval &lt;字节&gt;</code> 开始分析内存分配，且只按给定速度采样（默认值是 <code>524287</code>，即 [i]512 KB[/i]）；</li><li><code>/spark profiler stop --comment &lt;注释&gt;</code> 停止分析，并在浏览界面中填写注释；</li><li><code>/spark profiler stop --separate-parent-calls</code> 停止分析，并在浏览界面中将不同父方法调用的内容分开显示。（[i]已弃用[/i]）</li><li><code>/spark profiler stop --save-to-file</code> 将文件保存至本地文件夹而非上传至网络。</li></ul></details><h2 id="健康分析" tabindex="-1">健康分析 <a class="header-anchor" href="#健康分析" aria-label="Permalink to &quot;健康分析&quot;">​</a></h2><h3 id="spark-health" tabindex="-1"><code>/spark health</code> <a class="header-anchor" href="#spark-health" aria-label="Permalink to &quot;`/spark health`&quot;">​</a></h3><p>子命令 <code>health</code> 会产生一份服务器的健康报告，其中包含 TPS、CPU、内存和硬盘的使用情况。</p><p>执行命令所需权限为 <code>spark</code> 或 <code>spark.healthreport</code>。</p><p>你可以使用以下命令：</p><ul><li><code>/spark health --memory</code> 会让报告中附带 JVM 内存的使用情况；</li><li><code>/spark health --network</code> 会让报告中附带系统网络的使用情况。</li></ul><h3 id="spark-ping" tabindex="-1"><code>/spark ping</code> <a class="header-anchor" href="#spark-ping" aria-label="Permalink to &quot;`/spark ping`&quot;">​</a></h3><p>子命令 <code>ping</code> 会输出全体玩家延迟的平均循环时间（或是指定玩家的延迟），并取三位小数。</p><p>你可以使用以下命令：</p><ul><li><code>/spark ping</code> 来浏览有关所有玩家平均延迟的信息；</li><li><code>/spark ping --player &lt;玩家名称&gt;</code> 返回指定玩家的延迟循环时间。</li></ul><p>执行命令所需权限为 <code>spark</code> 或 <code>spark.ping</code>。</p><h3 id="spark-tps" tabindex="-1"><code>/spark tps</code> <a class="header-anchor" href="#spark-tps" aria-label="Permalink to &quot;`/spark tps`&quot;">​</a></h3><p>子命令 <code>tps</code> 会输出服务器 TPS（每秒刻数）比率和 CPU 的使用情况。</p><p>执行命令所需权限为 <code>spark</code> 或 <code>spark.tps</code>。</p><h3 id="spark-tickmonitor" tabindex="-1"><code>/spark tickmonitor</code> <a class="header-anchor" href="#spark-tickmonitor" aria-label="Permalink to &quot;`/spark tickmonitor`&quot;">​</a></h3><p>子命令 <code>tickmonitor</code> 可以控制刻监视器（Tick Monitor）。</p><p>执行命令所需权限为 <code>spark</code> 或 <code>spark.tickmonitor</code>。</p><p>在不带参数的情况下，执行这条命令，可以控制监视器的开和关。</p><p>你可以使用以下命令：</p><ul><li><code>/spark tickmonitor --threshold &lt;比例&gt;</code> 启动刻监视器，但只记录超过刻时间间隔一定百分比的刻；</li><li><code>/spark tickmonitor --threshold-tick &lt;毫秒&gt;</code> 启动刻监视器，但只记录 MSPT（每刻毫秒数，Milliseconds per Tick）超过给定参数的刻；</li><li><code>/spark tickmonitor --without-gc</code> 启动刻监视器，但禁用 GC（内存垃圾收集，Garbage Collection）活动的记录。</li></ul><h2 id="内存使用" tabindex="-1">内存使用 <a class="header-anchor" href="#内存使用" aria-label="Permalink to &quot;内存使用&quot;">​</a></h2><h3 id="spark-gc" tabindex="-1"><code>/spark gc</code> <a class="header-anchor" href="#spark-gc" aria-label="Permalink to &quot;`/spark gc`&quot;">​</a></h3><p>子命令 <code>gc</code> 会显示服务器 GC（内存垃圾收集，Garbage Collection）的历史记录。</p><p>执行命令所需权限为 <code>spark</code> 或 <code>spark.gc</code>。</p><h3 id="spark-gcmonitor" tabindex="-1"><code>/spark gcmonitor</code> <a class="header-anchor" href="#spark-gcmonitor" aria-label="Permalink to &quot;`/spark gcmonitor`&quot;">​</a></h3><p>子命令 <code>gcmonitor</code> 管理服务器的 GC（内存垃圾收集，Garbage Collection）监视器系统。</p><p>执行命令所需权限为 <code>spark</code> 或 <code>spark.gcmonitor</code>。</p><h3 id="spark-heapsummary" tabindex="-1"><code>/spark heapsummary</code> <a class="header-anchor" href="#spark-heapsummary" aria-label="Permalink to &quot;`/spark heapsummary`&quot;">​</a></h3><p>子命令 <code>heapsummary</code> 会产生一份内存（堆）转储摘要，并将它上传到浏览器中。</p><p>执行命令所需权限为 <code>spark</code> 或 <code>spark.heapsummary</code>。</p><h3 id="spark-heapdump" tabindex="-1"><code>/spark heapdump</code> <a class="header-anchor" href="#spark-heapdump" aria-label="Permalink to &quot;`/spark heapdump`&quot;">​</a></h3><p>子命令 <code>heapdump</code> 会产生一份堆转储（.hprof 格式的快照）文件，并将它保存在本地。</p><p>你可以使用以下命令：</p><ul><li><code>/spark heapdump --compress &lt;类型&gt;</code> 可以指定堆转储文件压缩为的格式。支持的未见类型有 gzip、xz 以及 lzma；</li><li><code>/spark heapdump --include-non-live</code> 可以指定所要包含的“非活跃”对象（不可访问且符合 GC 回收条件的对象）；[i]（已弃用）[/i]</li><li><code>/spark heapdump --run-gc-before</code> 可以让 JVM 在堆转储生成前启用 GC。[i]（已弃用）[/i]</li></ul><h2 id="杂项" tabindex="-1">杂项 <a class="header-anchor" href="#杂项" aria-label="Permalink to &quot;杂项&quot;">​</a></h2><h3 id="spark-activity" tabindex="-1"><code>/spark activity</code> <a class="header-anchor" href="#spark-activity" aria-label="Permalink to &quot;`/spark activity`&quot;">​</a></h3><p>子命令 <code>activity</code> 能显示 spark 最近活动的有关信息。</p><p>执行命令所需权限为 <code>spark</code> 或 <code>spark.activity</code>。</p><p>你可以使用以下命令：</p><ul><li><code>/spark activity --page &lt;页码&gt;</code> 可以浏览指定页面。</li></ul><h2 id="另见" tabindex="-1">另见 <a class="header-anchor" href="#另见" aria-label="Permalink to &quot;另见&quot;">​</a></h2><ul><li>有关<strong>刻</strong>和<strong>滴答</strong>的释义：<a href="https://zh.minecraft.wiki/w/%E5%88%BB" target="_blank" rel="noreferrer">https://zh.minecraft.wiki/w/刻</a></li><li>部分译名参考自站内搬运帖：<a href="https://www.mcbbs.net/thread-823209-1-1.html" target="_blank" rel="noreferrer">https://www.mcbbs.net/thread-823209-1-1.html</a></li><li>部分译名参考自中文维基：<a href="https://zh.minecraft.wiki/w/%E5%88%BB" target="_blank" rel="noreferrer">https://zh.minecraft.wiki/w/刻</a></li><li>部分译名参考自知乎文章 <em>《由浅入深了解GC原理》</em>：<a href="https://zhuanlan.zhihu.com/p/100475619" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/100475619</a></li></ul>',55)]))}const m=a(i,[["render",l]]);export{k as __pageData,m as default};
